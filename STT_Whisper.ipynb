{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c58af452-78b3-45b6-a9bd-83c3cfc9a107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\bibha\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\bibha\\anaconda3\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\bibha\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: soundfile in c:\\users\\bibha\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bibha\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install torch transformers librosa soundfile\n",
    "import torch\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f87cc4c-ac9a-4a6f-a6eb-8d41f71279d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/whisper-large\"  # Use the large model for best accuracy\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a2947a2-5d4d-4bc3-b28d-f1e8319a2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=16000)  # Load and resample to 16kHz\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a4d7376-0d41-48cb-925c-7af833a373e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(audio, chunk_length=30):\n",
    "    sr = 16000  \n",
    "    chunk_size = chunk_length * sr  \n",
    "    chunks = [audio[i:i + chunk_size] for i in range(0, len(audio), chunk_size)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd546e4b-779e-4d8e-989b-acbafb26914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio, language=None):\n",
    "    inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate transcription with optional language specification\n",
    "    if language:\n",
    "        predicted_ids = model.generate(inputs.input_features, language=language)\n",
    "    else:\n",
    "        predicted_ids = model.generate(inputs.input_features)\n",
    "    \n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    return transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f263824-dc6f-46cb-9501-38851ba467fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_any_audio(file_path, language=None):\n",
    "    \n",
    "    audio = load_audio(file_path)\n",
    "    \n",
    "    # Check if the audio is shorter than 30 seconds\n",
    "    if len(audio) <= 30 * 16000:  \n",
    "        print(\"Transcribing short audio...\")\n",
    "        transcription = transcribe_audio(audio, language=language)\n",
    "    else:\n",
    "        # Split the audio into chunks\n",
    "        chunks = split_audio(audio)\n",
    "        print(f\"Transcribing long audio in {len(chunks)} chunks...\")\n",
    "        \n",
    "        # Transcribe each chunk\n",
    "        full_transcription = \"\"\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            print(f\"Transcribing chunk {i + 1} of {len(chunks)}...\")\n",
    "            transcription = transcribe_audio(chunk, language=language)\n",
    "            full_transcription += transcription + \" \"\n",
    "        \n",
    "        transcription = full_transcription.strip()\n",
    "    \n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aab1d808-9fd2-4db9-a475-cfaf63cd873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "audio_path = \"C:\\\\Users\\\\bibha\\\\Downloads\\\\STT_Whisper_audio (online-audio-converter.com).mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70a6df02-9eb9-4895-8923-c0b8ec550066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the language (optional, e.g., \"fr\" for French, \"es\" for Spanish, \"hi\" for Hindi)\n",
    "language = None  # Set to None for auto-detection,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "877d5b29-4a75-42dd-b9dc-5ab12d39aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing long audio in 3 chunks...\n",
      "Transcribing chunk 1 of 3...\n",
      "Transcribing chunk 2 of 3...\n",
      "Transcribing chunk 3 of 3...\n",
      "Full Transcription: Hello everyone, my name is Biba Kumari. My project name is STT Whisper. This project demonstrates how to use Whispers model via Hugging Phase Transformers to convert MP3 audio files into text implemented in Python using a Jupyter notebook for ease of understanding and experimentation. It includes steps for loading and pre-processing audio files, transcribing them using the Whisper model and evaluating the model's  performance on custom audio inputs. The Whisper model supports the transcription and can automatically detect the language of the audio, making it versatile for applications like transcribing meetings, generating subtitles or aiding language learning. Ideal for AI ML enthusiasts, developers and researchers, this project provides a user-friendly, well-documented implementation that can be customized for specific  cases such as fine tuning for domain specific tasks or integrating into applications by offering a practical and accessible approach speech-to-text technology.\n"
     ]
    }
   ],
   "source": [
    "transcription = transcribe_any_audio(audio_path, language=language)\n",
    "print(\"Full Transcription:\", transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ba55c-0259-4333-9235-0b4250707377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
